<html>
<head>
<title>object_detection_api.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #a9b7c6;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
object_detection_api.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">{ 
 &quot;cells&quot;: [ 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: {}, 
   &quot;source&quot;: [ 
    &quot;# Table of contents\n&quot;, 
    &quot;1. [Introduction](#introduction)\n&quot;, 
    &quot;2. [Setting up environment](#preliminaries)\n&quot; 
   ] 
  }, 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: { 
    &quot;collapsed&quot;: true 
   }, 
   &quot;source&quot;: [ 
    &quot;#Problem Description &lt;a name=\&quot;introduction\&quot;&gt;&lt;/a&gt;\n&quot;, 
    &quot;\n&quot;, 
    &quot;- What does this project do?\n&quot;, 
    &quot;Computer vision has a lot of application for eg... -&gt; This project present a quick, easy way to make computer understand images and videos collected from the Internet or directly taken from computer's webcam. The goal of this project is to find the exact location and the type of the objects in an image\n&quot;, 
    &quot;\n&quot;, 
    &quot;\n&quot;, 
    &quot;* In order to achieve such classification and localization, we wil leverage the TensorFlow object detection  API. This is a Google's open source frame work built on top of TensorFlow which is focused on finding objects in images (estimating the chance that an object is in this position) and their bounding boxes. The framework offers some useful functions and these five pre-trained different models:\n&quot;, 
    &quot;    * Single Shot Multibox Detector (SSD) with MobileNets\n&quot;, 
    &quot;    * SSD with Interception V2\n&quot;, 
    &quot;    * Region-Based Fully Convolutional Networks (R-FCN) with Resnet 101\n&quot;, 
    &quot;    * Faster R-CNN with Resnet 101\n&quot;, 
    &quot;    * Faster R-CNN with Interception Resnet v2\n&quot;, 
    &quot;The model are in growing order of precision in detection and slower speed of execution of the detection process. \n&quot;, 
    &quot;\n&quot;, 
    &quot;* Given such a powerful tool made available by TensorFlow, our plan is to leverage its API by creating a class you can use for annotating images both visually and in an external file. By annotating we mean the following:\n&quot;, 
    &quot;    * Pointing out the objects in an image \n&quot;, 
    &quot;    * Reporting the level of confidence in the object recognition (only consider objects above a minimum probability threshold, which is set at 0.25)\n&quot;, 
    &quot;    * Outputting the coordinates of two opposite vertices of the bounding box for each image.\n&quot;, 
    &quot;    * Saving all such information in a text file in JSON format\n&quot;, 
    &quot;    * Visually representing the bounding box on the original image, if required.\n&quot;, 
    &quot;\n&quot;, 
    &quot;* The project are divided into 3 steps:\n&quot;, 
    &quot;    1. Download one of pre-trained models (available in .pb format - protobuf) and make it available in-memory as a TensorFlow session.\n&quot;, 
    &quot;    2. Reformulate the helper code provided by TensorFlow in order to make it easier to load labels, categories and visualization tools\n&quot;, 
    &quot;    3. Prepare a simple script sto demonstrate its uage with single images, videos and videos captured from a webcam.\n&quot;, 
    &quot;\n&quot; 
   ] 
  }, 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: {}, 
   &quot;source&quot;: [ 
    &quot;## Preliminaries &lt;a name=\&quot;priliminaries\&quot;&gt;&lt;/a&gt;\n&quot;, 
    &quot;- Download the Tensorflow object detection code.\n&quot;, 
    &quot;- Setting up  an environment: conda install...\n&quot;, 
    &quot;- Protobuf compilation\n&quot; 
   ] 
  }, 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: {}, 
   &quot;source&quot;: [ 
    &quot;## Provision of the project code\n&quot;, 
    &quot;\n&quot;, 
    &quot;Steps by steps showing code of *object_detection.py*&quot; 
   ] 
  }, 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: {}, 
   &quot;source&quot;: [ 
    &quot;## Result and applicatitons\n&quot;, 
    &quot;1. Annotating images with file_pipeline.py\n&quot;, 
    &quot;2. Annotating video with video_pipeline.py\n&quot;, 
    &quot;3. Annotating screenshot captured by webcam with webcam_pipeline.py\n&quot;, 
    &quot;4. Real-time webcam detection&quot; 
   ] 
  }, 
  { 
   &quot;cell_type&quot;: &quot;markdown&quot;, 
   &quot;metadata&quot;: {}, 
   &quot;source&quot;: [] 
  } 
 ], 
 &quot;metadata&quot;: { 
  &quot;kernelspec&quot;: { 
   &quot;display_name&quot;: &quot;Python 2&quot;, 
   &quot;language&quot;: &quot;python&quot;, 
   &quot;name&quot;: &quot;python2&quot; 
  }, 
  &quot;language_info&quot;: { 
   &quot;codemirror_mode&quot;: { 
    &quot;name&quot;: &quot;ipython&quot;, 
    &quot;version&quot;: 2 
   }, 
   &quot;file_extension&quot;: &quot;.py&quot;, 
   &quot;mimetype&quot;: &quot;text/x-python&quot;, 
   &quot;name&quot;: &quot;python&quot;, 
   &quot;nbconvert_exporter&quot;: &quot;python&quot;, 
   &quot;pygments_lexer&quot;: &quot;ipython2&quot;, 
   &quot;version&quot;: &quot;2.7.6&quot; 
  } 
 }, 
 &quot;nbformat&quot;: 4, 
 &quot;nbformat_minor&quot;: 0 
} 
</span></pre>
</body>
</html>